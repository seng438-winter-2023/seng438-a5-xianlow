**SENG 438- Software Testing, Reliability, and Quality**

**Lab. Report \#5 – Software Reliability Assessment**

| Group \#:       |   |
|-----------------|---|
| Student Names:  |   |
|         Xian Wei Low        |  30113016 |
|          Akashdeep Singh       |  30128444 |
|        Abdul Moeiz         |  	30113088 |
| Cale Morash | 30066719 |

# Introduction
  In this lab, we will be comparing the results that we are getting by using Reliability Growth Testing and Reliability Demonstration Charts. Firstly, we will have to convert the values given to us so we can could use it in the C-SFRAT tool to compare models. The reliability growth testing will require calculations to determine the range. Then we will have to figure out our target failure rate which we will plot using the C-SFRAT tool. Lastly, we will look at the reliability demonstration chart which will require us to change our MTTF value to see how the values will impact our data. 
# 

# Assessment Using Reliability Growth Testing 
  Using the C-SFRAT tool’s Model Comparison tab to compare the IFR Salvia & Bollinger, IFR generalized Salvia & Bollinger, S Distribution, Discrete Weibull Order 2 and Type III, Geometric, Negative Binomial (Order 2), and Truncated Logistic models, we found that S Distribution and Truncated Logistic had the highest log likelihood. We selected these two models as they are the best fit for our data.
![Model comparison](https://github.com/seng438-winter-2023/seng438-a5-xianlow/blob/main/media/C-SFRATModelComparison.png)
The MVF and Intensity plot for our input:
![MVF plot](https://github.com/seng438-winter-2023/seng438-a5-xianlow/blob/main/media/MvfIntensityPlot.png)
![Intensity plot](https://github.com/seng438-winter-2023/seng438-a5-xianlow/blob/main/media/intensityPlot.png)
The MVF and Intensity plot for TL and S:
![MVF plot for TL and S](https://github.com/seng438-winter-2023/seng438-a5-xianlow/blob/main/media/MvfTlsPlot.png)
![Intensity plot for TL and S](https://github.com/seng438-winter-2023/seng438-a5-xianlow/blob/main/media/intensityTlsPlot.png)

Discussion on Range Analysis:
Range analysis was done using the Laplace method with the following formula for failure counts data:
![Range analysis](https://github.com/seng438-winter-2023/seng438-a5-xianlow/blob/main/media/rangeAnalysis.png)
![Laplace analysis](https://github.com/seng438-winter-2023/seng438-a5-xianlow/blob/main/media/laplaceAnalysis.png)
Upon plotting the results, we found that the failure intensity became relatively stable after time interval 30. There are improvements to the reliability from intervals 1-4 and 20-27. We decided that an acceptable range with enough data points would be the interval from 1-30. 

Discussion on Target Failure Rate:
![Failure rate](https://github.com/seng438-winter-2023/seng438-a5-xianlow/blob/main/media/targetFailureRate.png)
With 133 total failures in the data over 62 time intervals each of which is a week or 168 hours long, we get an average failure rate of 0.47 and failure intensity of 2.14. 

The intensity plot with a target intensity of 2.0 predicts that it could be achieved in one interval:
![Failure rate 2](https://github.com/seng438-winter-2023/seng438-a5-xianlow/blob/main/media/targetFailureRate2.png)

The intensity plot with a target intensity of 2.0 predicts that it could be achieved in 30 intervals:
![Failure rate 3](https://github.com/seng438-winter-2023/seng438-a5-xianlow/blob/main/media/targetFailureRate3.png)

Although the failure intensity is high, each interval time is a week long. When converted to hours, the failure intensity is 0.0128, so we concluded that the SUT is fairly reliable and can be sustained for 30 more time intervals until the intensity is reduced to 1.5/week.
# Assessment Using Reliability Demonstration Chart 


The parameters we used for the reliability demonstration chart are a discrimination ratio of 2.0, a customer risk of 0.1, and a developer risk of 0.1. Through trial and error, we got an MTTF of 1 error in 280000 seconds which is equal to 1 error in 0.4630 weeks.  

![RDC1](https://github.com/seng438-winter-2023/seng438-a5-xianlow/blob/main/media/Rdc.png)

Double MTTF:

![RDC2](https://github.com/seng438-winter-2023/seng438-a5-xianlow/blob/main/media/Rdc2.png)

Half MTTF:

![RDC3](https://github.com/seng438-winter-2023/seng438-a5-xianlow/blob/main/media/Rdc3.png)
# 

# Comparison of Results
  When comparing the Reliability Growth Testing in part 1 with the Reliability Demonstration Chart in part 2, both prove the notion that the system being tested becomes more reliable over time. This is explicitly seen in the decrease in failures across the intensity plot in part 1, and the shift from the reject to the accept zones in the plots for part 2
# Discussion on Similarity and Differences of the Two Techniques
RGT and RDC are similar to the fact that they both test the system for the doing calculations with probability of failures and the MTTF given the failure times as input. Thus both are used to assess the reliability of the product/system and find any improvevepments.
However, they are different in the fact that specific outputs are different. While RGT aims to find/improve the reliability of the system as time passes, RDC focuses on evaluates the quality at which the system satisfies the relibality requirements at a discrete point in time. In the same way, the plots of RGT show the progress of the system's reliability over time, whereas the plots of RDC show the reliability of the system at the specific/discret point in time.

# How the team work/effort was divided and managed
  In the lab, we have divided the work accordingly based on what was needed. Akash and Xian used C-SFRAT for the Reliability Growth Testing, while Abdul and Cale used RDC tool for the Reliability Growth Testing. Each group used their own device to perform the testing to later compare and verify the similarity of outputs.
# 

# Difficulties encountered, challenges overcome, and lessons learned
  Within this lab, there were many challenges that we have faced. THe major problem that we have encountered is understanding the information given to us and converting into valid values that we can use in SRA tools. With some time, we have converted the values into an xlsx format to place into the C-SFRAT tool to compare models. 
  Also some of our members unfortunately got ill or had external personal related commitments, which were reasonable and hence full attendance at the demo was not possible at that event of time. However, one our our members was thankfully able to attend the demo.
# Comments/feedback on the lab itself
  Compared to every lab we have had this semester, this will probably be the hardest out of all of them. Many attributes of this lab contributes to this. One, the instructions are very vague compared to the rest of the other labs. Another is that the values that have been provided is very hard to under what value is what. This makes the creation of the table to be very hard to do.
